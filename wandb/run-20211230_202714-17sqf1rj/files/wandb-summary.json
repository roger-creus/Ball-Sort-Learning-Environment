{"policy_loss": 0.0018288289429619908, "value_loss": 3.0419923859881237e-05, "running_reward": 107.78139100121709, "mean_entropy": 2.0826101303100586, "ratio": 1.005192518234253, "_runtime": 271, "_timestamp": 1640892705, "_step": 153}