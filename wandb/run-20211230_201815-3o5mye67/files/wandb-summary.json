{"policy_loss": 0.0015477503184229136, "value_loss": 2.573913704395636e-08, "running_reward": 135.72000974510863, "mean_entropy": 4.365720272064209, "ratio": 1.0019843578338623, "_runtime": 284, "_timestamp": 1640892179, "_step": 328}